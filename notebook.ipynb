{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests from quotes.py not working so getting quotes here after downloading .html files from website manually\n",
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import csv\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.read_csv('quotes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.to_json('quotes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022\n",
    "with open('365 Inspirational and Fascinating Quotes for 2022 - Inc. Australia.html') as f:\n",
    "    soup = BeautifulSoup(f)\n",
    "\n",
    "# h2_tags = soup.find_all(attrs={\"class\":\"inc_article_body\"})\n",
    "h2_tags = soup.find_all('h2')\n",
    "# len(h2_tags)\n",
    "\n",
    "# Initialize lists to store dates and quotes\n",
    "dates = []\n",
    "quotes = []\n",
    "\n",
    "# Iterate through each <h2> tag\n",
    "for h2 in h2_tags:\n",
    "    # Get the date from the <h2> tag\n",
    "    date = h2.text.strip()\n",
    "    # date = date.split(' (', 1)[0]\n",
    "    # Sunday, January 01, 2024\n",
    "    date_format = \"%A, %B %d, %Y\"\n",
    "\n",
    "    parsed_date = datetime.strptime(date, date_format)\n",
    "    dates.append(parsed_date)\n",
    "\n",
    "    # parse date into format\n",
    "    \n",
    "    # Find the next <p> tag (which contains the quote)\n",
    "    next_p = h2.find_next_sibling('p')\n",
    "    \n",
    "    # Get the quote from the <p> tag\n",
    "    if next_p:\n",
    "        quote = next_p.text.strip()# .encode('utf-8')\n",
    "        quotes.append(quote)\n",
    "\n",
    "\n",
    "with open('quotes_2022.csv', mode='w', newline='\\n') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date', 'Quote'])  # write header\n",
    "    writer.writerows(zip(dates, quotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023\n",
    "with open('365 Best Inspirational Quotes for 2023 - Inc. Australia.html') as f:\n",
    "    soup = BeautifulSoup(f)\n",
    "\n",
    "# h2_tags = soup.find_all(attrs={\"class\":\"inc_article_body\"})\n",
    "h2_tags = soup.find_all('h2')\n",
    "# len(h2_tags)\n",
    "\n",
    "# Initialize lists to store dates and quotes\n",
    "dates = []\n",
    "quotes = []\n",
    "\n",
    "# Iterate through each <h2> tag\n",
    "for h2 in h2_tags:\n",
    "    # Get the date from the <h2> tag\n",
    "    date = h2.text.strip()\n",
    "    # date = date.split(' (', 1)[0]\n",
    "    # format: January 1, 2024 (Sunday)\n",
    "    date_format = \"%B %d, %Y (%A)\"\n",
    "\n",
    "    parsed_date = datetime.strptime(date, date_format)  # read the date based on the format\n",
    "    parsed_date2 = parsed_date.strftime(\"%Y-%m-%d\")   # save as date without the timestamp only the yyyy-mm-dd\n",
    "    dates.append(parsed_date2)\n",
    "\n",
    "    # parse date into format\n",
    "    \n",
    "    # Find the next <p> tag (which contains the quote)\n",
    "    next_p = h2.find_next_sibling('p')\n",
    "    \n",
    "    # Get the quote from the <p> tag\n",
    "    if next_p:\n",
    "        quote = next_p.text.strip()# .encode('utf-8')\n",
    "        quotes.append(quote)\n",
    "\n",
    "\n",
    "with open('quotes_2023.csv', mode='w', newline='\\n') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date', 'Quote'])  # write header\n",
    "    writer.writerows(zip(dates, quotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024\n",
    "with open('366 Inspirational Quotes for 2024 - Inc. Australia.html') as f:\n",
    "    soup = BeautifulSoup(f)\n",
    "\n",
    "# h2_tags = soup.find_all(attrs={\"class\":\"inc_article_body\"})\n",
    "h2_tags = soup.find_all('h2')\n",
    "# len(h2_tags)\n",
    "\n",
    "# Initialize lists to store dates and quotes\n",
    "dates = []\n",
    "quotes = []\n",
    "\n",
    "# Iterate through each <h2> tag\n",
    "for h2 in h2_tags:\n",
    "    # Get the date from the <h2> tag\n",
    "    date = h2.text.strip()\n",
    "    # date = date.split(' (', 1)[0]\n",
    "    date_format = \"%A %B %d, %Y\"\n",
    "\n",
    "    parsed_date = datetime.strptime(date, date_format)  # read the date based on the format\n",
    "    parsed_date2 = parsed_date.strftime(\"%Y-%m-%d\")   # save as date without the timestamp only the yyyy-mm-dd\n",
    "    dates.append(parsed_date2)\n",
    "\n",
    "    # parse date into format\n",
    "    \n",
    "    # Find the next <p> tag (which contains the quote)\n",
    "    next_p = h2.find_next_sibling('p')\n",
    "    \n",
    "    # Get the quote from the <p> tag\n",
    "    if next_p:\n",
    "        quote = next_p.text.strip()# .encode('utf-8')\n",
    "        quotes.append(quote)\n",
    "\n",
    "\n",
    "with open('quotes_2024.csv', mode='w', newline='\\n') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date', 'Quote'])  # write header\n",
    "    writer.writerows(zip(dates, quotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "# 2020\n",
    "with open('366 Top Inspirational Quotes and Motivational Quotes for Every Single Day in 2020 - Inc. Australia.html') as f:\n",
    "    soup = BeautifulSoup(f)\n",
    "\n",
    "# h2_tags = soup.find_all(attrs={\"class\":\"inc_article_body\"})\n",
    "h2_tags = soup.find_all('h2')\n",
    "# len(h2_tags)\n",
    "\n",
    "# Initialize lists to store dates and quotes\n",
    "dates = []\n",
    "quotes = []\n",
    "authors = []\n",
    "\n",
    "# Iterate through each <h2> tag\n",
    "for h2 in h2_tags:\n",
    "    # Get the date from the <h2> tag\n",
    "    date = h2.text.strip()\n",
    "    date = date.split(' (', 1)[0]\n",
    "    date_format = \"%A, %B %d, %Y\"\n",
    "\n",
    "    parsed_date = datetime.strptime(date, date_format)  # read the date based on the format\n",
    "    parsed_date2 = parsed_date.strftime(\"%Y-%m-%d\")   # save as date without the timestamp only the yyyy-mm-dd\n",
    "    dates.append(parsed_date2)\n",
    "\n",
    "    # parse date into format\n",
    "    \n",
    "    # Find the next <p> tag (which contains the quote)\n",
    "    next_p = h2.find_next_sibling('p')\n",
    "    \n",
    "    # Get the quote from the <p> tag\n",
    "    if next_p:\n",
    "        quote = next_p.text.strip()# .encode('utf-8')\n",
    "        quotes.append(quote)\n",
    "        \n",
    "\n",
    "\n",
    "with open('quotes_2020.csv', mode='w', newline='\\n') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date', 'Quote'])  # write header\n",
    "    writer.writerows(zip(dates, quotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quotes.csv')\n",
    "df.to_json('quotes.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
